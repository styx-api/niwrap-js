// This file was auto generated by Styx.
// Do not edit this file directly.

import { Runner, Execution, Metadata, InputPathType, OutputPathType, getGlobalRunner } from 'styxdefs';

const ANTS_JOINT_TENSOR_FUSION_METADATA: Metadata = {
    id: "5d343b97b1984cf23521db0f60519ddbabba3a2e.boutiques",
    name: "antsJointTensorFusion",
    package: "ants",
    container_image_tag: "antsx/ants:v2.5.3",
};


interface AntsJointTensorFusionParameters {
    "@type"?: "ants/antsJointTensorFusion";
    "dimensionality"?: 2 | 3 | 4 | null | undefined;
    "target_image": Array<string>;
    "atlas_image": Array<string>;
    "atlas_segmentation": InputPathType;
    "alpha"?: number | null | undefined;
    "beta"?: number | null | undefined;
    "retain_label_posterior_images"?: 0 | 1 | null | undefined;
    "retain_atlas_voting_images"?: 0 | 1 | null | undefined;
    "constrain_nonnegative"?: 0 | 1 | null | undefined;
    "log_euclidean"?: 0 | 1 | null | undefined;
    "patch_radius"?: string | null | undefined;
    "patch_metric"?: "PC" | "MSQ" | null | undefined;
    "search_radius"?: string | null | undefined;
    "exclusion_image"?: string | null | undefined;
    "mask_image"?: InputPathType | null | undefined;
    "output": string;
    "verbose"?: 0 | 1 | null | undefined;
}
type AntsJointTensorFusionParametersTagged = Required<Pick<AntsJointTensorFusionParameters, '@type'>> & AntsJointTensorFusionParameters;


/**
 * Output object returned when calling `AntsJointTensorFusionParameters(...)`.
 *
 * @interface
 */
interface AntsJointTensorFusionOutputs {
    /**
     * Output root folder. This is the root folder for all outputs.
     */
    root: OutputPathType;
    /**
     * The label fusion image output.
     */
    label_fusion_image: OutputPathType;
    /**
     * The intensity fusion image output.
     */
    intensity_fusion_image: OutputPathType;
    /**
     * The label posterior probability images.
     */
    label_posterior_probability_image: OutputPathType;
    /**
     * The atlas voting weight images.
     */
    atlas_voting_weight_image: OutputPathType;
}


/**
 * Build parameters.
 *
 * @param target_image The target image (or multimodal target images) assumed to be aligned to a common image domain.
 * @param atlas_image The atlas image (or multimodal atlas images) assumed to be aligned to a common image domain.
 * @param atlas_segmentation The atlas segmentation images. For performing label fusion the number of specified segmentations should be identical to the number of atlas image sets.
 * @param output The output is the intensity and/or label fusion image. Additional optional outputs include the label posterior probability images and the atlas voting weight images.
 * @param dimensionality This option forces the image to be treated as a specified-dimensional image. If not specified, the program tries to infer the dimensionality from the input image.
 * @param alpha Regularization term added to matrix Mx for calculating the inverse. Default = 0.1
 * @param beta Exponent for mapping intensity difference to the joint error. Default = 2.0
 * @param retain_label_posterior_images Retain label posterior probability images. Requires atlas segmentations to be specified. Default = false
 * @param retain_atlas_voting_images Retain atlas voting images. Default = false
 * @param constrain_nonnegative Constrain solution to non-negative weights.
 * @param log_euclidean Use log Euclidean space for tensor math.
 * @param patch_radius Patch radius for similarity measures. Default = 2x2x2
 * @param patch_metric Metric to be used in determining the most similar neighborhood patch. Options include Pearson's correlation (PC) and mean squares (MSQ). Default = PC.
 * @param search_radius Search radius for similarity measures. Default = 3x3x3
 * @param exclusion_image Specify an exclusion region for the given label.
 * @param mask_image If a mask image is specified, fusion is only performed in the mask region.
 * @param verbose Verbose output.
 *
 * @returns Parameter dictionary
 */
function ants_joint_tensor_fusion_params(
    target_image: Array<string>,
    atlas_image: Array<string>,
    atlas_segmentation: InputPathType,
    output: string,
    dimensionality: 2 | 3 | 4 | null = null,
    alpha: number | null = null,
    beta: number | null = null,
    retain_label_posterior_images: 0 | 1 | null = null,
    retain_atlas_voting_images: 0 | 1 | null = null,
    constrain_nonnegative: 0 | 1 | null = null,
    log_euclidean: 0 | 1 | null = null,
    patch_radius: string | null = null,
    patch_metric: "PC" | "MSQ" | null = null,
    search_radius: string | null = null,
    exclusion_image: string | null = null,
    mask_image: InputPathType | null = null,
    verbose: 0 | 1 | null = null,
): AntsJointTensorFusionParametersTagged {
    const params = {
        "@type": "ants/antsJointTensorFusion" as const,
        "target_image": target_image,
        "atlas_image": atlas_image,
        "atlas_segmentation": atlas_segmentation,
        "output": output,
    };
    if (dimensionality !== null) {
        params["dimensionality"] = dimensionality;
    }
    if (alpha !== null) {
        params["alpha"] = alpha;
    }
    if (beta !== null) {
        params["beta"] = beta;
    }
    if (retain_label_posterior_images !== null) {
        params["retain_label_posterior_images"] = retain_label_posterior_images;
    }
    if (retain_atlas_voting_images !== null) {
        params["retain_atlas_voting_images"] = retain_atlas_voting_images;
    }
    if (constrain_nonnegative !== null) {
        params["constrain_nonnegative"] = constrain_nonnegative;
    }
    if (log_euclidean !== null) {
        params["log_euclidean"] = log_euclidean;
    }
    if (patch_radius !== null) {
        params["patch_radius"] = patch_radius;
    }
    if (patch_metric !== null) {
        params["patch_metric"] = patch_metric;
    }
    if (search_radius !== null) {
        params["search_radius"] = search_radius;
    }
    if (exclusion_image !== null) {
        params["exclusion_image"] = exclusion_image;
    }
    if (mask_image !== null) {
        params["mask_image"] = mask_image;
    }
    if (verbose !== null) {
        params["verbose"] = verbose;
    }
    return params;
}


/**
 * Build command-line arguments from parameters.
 *
 * @param params The parameters.
 * @param execution The execution object for resolving input paths.
 *
 * @returns Command-line arguments.
 */
function ants_joint_tensor_fusion_cargs(
    params: AntsJointTensorFusionParameters,
    execution: Execution,
): string[] {
    const cargs: string[] = [];
    cargs.push("antsJointTensorFusion");
    if ((params["dimensionality"] ?? null) !== null) {
        cargs.push(
            "--image-dimensionality",
            String((params["dimensionality"] ?? null))
        );
    }
    cargs.push(
        "-t",
        (params["target_image"] ?? null).join(",")
    );
    cargs.push(
        "-g",
        (params["atlas_image"] ?? null).join(",")
    );
    cargs.push(
        "-l",
        execution.inputFile((params["atlas_segmentation"] ?? null))
    );
    if ((params["alpha"] ?? null) !== null) {
        cargs.push(
            "-a",
            String((params["alpha"] ?? null))
        );
    }
    if ((params["beta"] ?? null) !== null) {
        cargs.push(
            "-b",
            String((params["beta"] ?? null))
        );
    }
    if ((params["retain_label_posterior_images"] ?? null) !== null) {
        cargs.push(
            "-r",
            String((params["retain_label_posterior_images"] ?? null))
        );
    }
    if ((params["retain_atlas_voting_images"] ?? null) !== null) {
        cargs.push(
            "-f",
            String((params["retain_atlas_voting_images"] ?? null))
        );
    }
    if ((params["constrain_nonnegative"] ?? null) !== null) {
        cargs.push(
            "-c",
            String((params["constrain_nonnegative"] ?? null))
        );
    }
    if ((params["log_euclidean"] ?? null) !== null) {
        cargs.push(
            "-u",
            String((params["log_euclidean"] ?? null))
        );
    }
    if ((params["patch_radius"] ?? null) !== null) {
        cargs.push(
            "-p",
            (params["patch_radius"] ?? null)
        );
    }
    if ((params["patch_metric"] ?? null) !== null) {
        cargs.push(
            "-m",
            (params["patch_metric"] ?? null)
        );
    }
    if ((params["search_radius"] ?? null) !== null) {
        cargs.push(
            "-s",
            (params["search_radius"] ?? null)
        );
    }
    if ((params["exclusion_image"] ?? null) !== null) {
        cargs.push(
            "-e",
            (params["exclusion_image"] ?? null)
        );
    }
    if ((params["mask_image"] ?? null) !== null) {
        cargs.push(
            "-x",
            execution.inputFile((params["mask_image"] ?? null))
        );
    }
    cargs.push(
        "-o",
        (params["output"] ?? null)
    );
    if ((params["verbose"] ?? null) !== null) {
        cargs.push(
            "-v",
            String((params["verbose"] ?? null))
        );
    }
    return cargs;
}


/**
 * Build outputs object containing output file paths and possibly stdout/stderr.
 *
 * @param params The parameters.
 * @param execution The execution object for resolving input paths.
 *
 * @returns Outputs object.
 */
function ants_joint_tensor_fusion_outputs(
    params: AntsJointTensorFusionParameters,
    execution: Execution,
): AntsJointTensorFusionOutputs {
    const ret: AntsJointTensorFusionOutputs = {
        root: execution.outputFile("."),
        label_fusion_image: execution.outputFile([(params["output"] ?? null), "_LabelFusion.nii.gz"].join('')),
        intensity_fusion_image: execution.outputFile([(params["output"] ?? null), "_IntensityFusion.nii.gz"].join('')),
        label_posterior_probability_image: execution.outputFile([(params["output"] ?? null), "_LabelPosterior.nii.gz"].join('')),
        atlas_voting_weight_image: execution.outputFile([(params["output"] ?? null), "_AtlasVoting.nii.gz"].join('')),
    };
    return ret;
}


/**
 * antsJointTensorFusion
 *
 * antsJointTensorFusion is an image fusion algorithm developed by Hongzhi Wang and Paul Yushkevich which won segmentation challenges at MICCAI 2012 and MICCAI 2013. The original label fusion framework was extended to accommodate intensities by Brian Avants. This implementation is based on the original ITK-style implementation and ANTsR implementation.
 *
 * Author: ANTs Developers
 *
 * URL: https://github.com/ANTsX/ANTs
 *
 * @param params The parameters.
 * @param runner Command runner
 *
 * @returns NamedTuple of outputs (described in `AntsJointTensorFusionOutputs`).
 */
function ants_joint_tensor_fusion_execute(
    params: AntsJointTensorFusionParameters,
    runner: Runner | null = null,
): AntsJointTensorFusionOutputs {
    runner = runner || getGlobalRunner();
    const execution = runner.startExecution(ANTS_JOINT_TENSOR_FUSION_METADATA);
    params = execution.params(params)
    const cargs = ants_joint_tensor_fusion_cargs(params, execution)
    const ret = ants_joint_tensor_fusion_outputs(params, execution)
    execution.run(cargs, undefined);
    return ret;
}


/**
 * antsJointTensorFusion
 *
 * antsJointTensorFusion is an image fusion algorithm developed by Hongzhi Wang and Paul Yushkevich which won segmentation challenges at MICCAI 2012 and MICCAI 2013. The original label fusion framework was extended to accommodate intensities by Brian Avants. This implementation is based on the original ITK-style implementation and ANTsR implementation.
 *
 * Author: ANTs Developers
 *
 * URL: https://github.com/ANTsX/ANTs
 *
 * @param target_image The target image (or multimodal target images) assumed to be aligned to a common image domain.
 * @param atlas_image The atlas image (or multimodal atlas images) assumed to be aligned to a common image domain.
 * @param atlas_segmentation The atlas segmentation images. For performing label fusion the number of specified segmentations should be identical to the number of atlas image sets.
 * @param output The output is the intensity and/or label fusion image. Additional optional outputs include the label posterior probability images and the atlas voting weight images.
 * @param dimensionality This option forces the image to be treated as a specified-dimensional image. If not specified, the program tries to infer the dimensionality from the input image.
 * @param alpha Regularization term added to matrix Mx for calculating the inverse. Default = 0.1
 * @param beta Exponent for mapping intensity difference to the joint error. Default = 2.0
 * @param retain_label_posterior_images Retain label posterior probability images. Requires atlas segmentations to be specified. Default = false
 * @param retain_atlas_voting_images Retain atlas voting images. Default = false
 * @param constrain_nonnegative Constrain solution to non-negative weights.
 * @param log_euclidean Use log Euclidean space for tensor math.
 * @param patch_radius Patch radius for similarity measures. Default = 2x2x2
 * @param patch_metric Metric to be used in determining the most similar neighborhood patch. Options include Pearson's correlation (PC) and mean squares (MSQ). Default = PC.
 * @param search_radius Search radius for similarity measures. Default = 3x3x3
 * @param exclusion_image Specify an exclusion region for the given label.
 * @param mask_image If a mask image is specified, fusion is only performed in the mask region.
 * @param verbose Verbose output.
 * @param runner Command runner
 *
 * @returns NamedTuple of outputs (described in `AntsJointTensorFusionOutputs`).
 */
function ants_joint_tensor_fusion(
    target_image: Array<string>,
    atlas_image: Array<string>,
    atlas_segmentation: InputPathType,
    output: string,
    dimensionality: 2 | 3 | 4 | null = null,
    alpha: number | null = null,
    beta: number | null = null,
    retain_label_posterior_images: 0 | 1 | null = null,
    retain_atlas_voting_images: 0 | 1 | null = null,
    constrain_nonnegative: 0 | 1 | null = null,
    log_euclidean: 0 | 1 | null = null,
    patch_radius: string | null = null,
    patch_metric: "PC" | "MSQ" | null = null,
    search_radius: string | null = null,
    exclusion_image: string | null = null,
    mask_image: InputPathType | null = null,
    verbose: 0 | 1 | null = null,
    runner: Runner | null = null,
): AntsJointTensorFusionOutputs {
    const params = ants_joint_tensor_fusion_params(target_image, atlas_image, atlas_segmentation, output, dimensionality, alpha, beta, retain_label_posterior_images, retain_atlas_voting_images, constrain_nonnegative, log_euclidean, patch_radius, patch_metric, search_radius, exclusion_image, mask_image, verbose)
    return ants_joint_tensor_fusion_execute(params, runner);
}


export {
      ANTS_JOINT_TENSOR_FUSION_METADATA,
      AntsJointTensorFusionOutputs,
      ants_joint_tensor_fusion,
      ants_joint_tensor_fusion_execute,
      ants_joint_tensor_fusion_params,
};
